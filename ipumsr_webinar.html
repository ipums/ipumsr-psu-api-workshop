<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Using IPUMS data in R with ipumsr</title>
    <meta charset="utf-8" />
    <meta name="author" content="Derek Burk, Dan Ehrlich, &amp; Kara Fisher" />
    <meta name="date" content="2021-10-12" />
    <script src="libs/header-attrs-2.11/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
    <script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
    <link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
    <script src="libs/datatables-binding-0.19/datatables.js"></script>
    <script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
    <link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
    <link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
    <script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
    <link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
    <script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Using IPUMS data in R with ipumsr
### Derek Burk, Dan Ehrlich, &amp; Kara Fisher
### 10/12/2021

---







&lt;style&gt;
.grid-logo {
  background-image: url(logos/grid.png);
  background-size: cover;
  height: 252px;
  width: 220px;
}
&lt;/style&gt;

&lt;style&gt;
.derek-pet {
  background-image: url(logos/derek2.jpg);
  background-size: cover;
  height: 196;
  width: 240;
}
&lt;/style&gt;



&lt;style&gt;
.isrdi-logo {
  background-image: url(logos/isrdi2.jpg);
  background-size: cover;
  height: 186px;
  width: 604px;
  position: absolute;
  bottom: 15px;
  left: 15;
}
&lt;/style&gt;



&lt;style&gt;
.names {
  font-size: 1.5em;
}
&lt;/style&gt;

&lt;style&gt;
  .greyed-out {
    color: #D3D3D3;
    text-indent: 20px;
  }
&lt;/style&gt;

&lt;style&gt;
  .strong {
    color: #000000;
    text-indent: 20px;
  }
&lt;/style&gt;




# Who we are

.isrdi-logo[]

.left-column[
Derek Burk, 
PhD, 
Sociology
]


.derek-pet[asdasd]



---

# Who we are

.isrdi-logo[]

.left-column[
Derek Burk, 
PhD, 
Sociology

Dan Ehrlich, 
MA, 
Anthropology
]

---

# Who we are

.isrdi-logo[]

.left-column[

Derek Burk, 
PhD, 
Sociology


Dan Ehrlich, 
MA, 
Anthropology


Kara Fisher, 
MPH, 
Public Health
]



---

# Overview

1. What is IPUMS?

--

2. What is ipumsr, and why use it?

--

3. Reading data into R

--

4. Exploring and manipulating metadata

--

5. Brief analysis example

--

6. Working with IPUMS geographic data

--

7. Preview of IPUMS API functionality

--

8. Q &amp; A

---

# Overview



.greyed-out[


.strong[`1.` What is IPUMS?]

`2.` What is ipumsr, and why use it?

`3.` Reading data into R

`4.` Exploring and manipulating metadata

`5.` Brief analysis example

`6.` Working with IPUMS geographic data

`7.` Preview of IPUMS API functionality

]


---



class: center

# What is IPUMS?

--

## IPUMS is **data**

--

## from censuses and surveys around the world,

--

## integrated across space and time,

--

## thoroughly documented,

--

## and available for free at ipums.org

???

ipums has grown substantially over the past 20?? years, and our data is organized within 9 projects

---
# 
![IPUMS US Project logo](logos/usa.jpg)

- U.S. Census and American Community Survey **microdata** from 1850 to the present.

- 180,755,919 unique person records from decennial census and Anual community Survey.

- 191,983,898 historical personrecords from full count decennial census from 1850-1940 (1890 census lost due to fire).

- https://usa.ipums.org/usa/

???




---

# 
![IPUMS CPS project logo](logos/cps.jpg)

- Current Population Survey **microdata** from 1962 to the present.

- Monthly labor force surveys and supplements.



---

# 
![IPUMS NHGIS project logo](logos/int.jpg)


- Census **microdata** covering a102 countries from 1960 to the present 



- International historic **microdata** from the 19th and early 20th centuries for *9* countries.

--

- Labor Force surveys provide high resolution **microdata** about work conditions

  - Adminstered quarterly (usually) with records going back at least 10 years (usually)
  - Currently available for Italy (2011-2020) &amp; Spain (2005-2020)
  - Mexico (2005-2020) coming soon!




---
# 
![IPUMS Global Health project logo](logos/dhs.jpg)

- Demographic and Health Surveys (DHS) provide integrated **microdata** for analysis across time and space.
  - From the 1980s to the present.
  - Covering Africa and South Asia
  
- Performance Monitoring for Action (PMA) surveys
  - Focus on fertility, contraception, hygiene, and health
  - Administered frequently to monitor trends in select high-fertility countries.
  - https://ipums.github.io/pma-data-hub/index.html#category:PMA_Publications


---
# 
![IPUMS Health Surveys project logo](logos/health.jpg)

- Health **survey** data from the National Health Interview Survey (NHIS) from the 1960s to the present and the Medical Expenditure Panel Survey (MEPS) from 1996.

- Supplements on cost of healthcare.

???


---

# 
![IPUMS Higher Ed project logo](logos/highered.jpg)

- Scientists and Engineers Statistical Data System (SESTAT), the leading surveys for studying the science and engineering (STEM) workforce in the United States

- Data from the National Surveys of College Graduates (NSCG), Recent College Graduates (NSRCG) and Doctorate Recipients (SDR) are integrated from 1993 to the present.



---
# 
![IPUMS Time Use project logo](logos/time_use.jpg)

- Historical and contemporary time use data from 1965 to the present.

- Extensive time diary data from respondents in the US and *7* other countries.

---
#
![IPUMS NHGIS project logo](logos/nhgis.jpg)

- Summary tables and time series of population, housing, agriculture, and economic data 

- GIS Shapefiles for all levels of US geography, including tracts, from 1790 to the present

---

# 
![IPUMS IHGIS project logo](logos/ihgis.jpg)

- **Summary** data tables from population and housing censuses as well as agricultural censuses from around the world

- Integrated GIS **shapefiles.**

---
# So What is Ipums?

.pull-right[

.grid[]
]

.pull-left[
- IPUMS is **a lot** of data

- United in consistently documented metadata
]

---

# So What is Ipums?

.pull-right[

.grid[]
]

.pull-left[
- IPUMS is **a lot** of data

- United in consistently documented metadata

- *What's the best way to interact with IPUMS data?*
]




???

So ipums really is **data** and a whole lot of it. These 9 different projects interact with different types of data and at different scales but they are united in 

---


class: center, middle

# Poll: Which IPUMS data collections have you used?

---


# Overview

.greyed-out[


`1.` What is IPUMS?

.strong[`2.` What is ipumsr, and why use it?]

`3.` Reading data into R

`4.` Exploring and manipulating metadata

`5.` Brief analysis example

`6.` Working with IPUMS geographic data

`7.` Preview of IPUMS API functionality

]


---



# What is ipumsr?

- R package developed by Greg Freedman Ellis

--

- Released in 2017

--

- Over 90,000 CRAN downloads

--

- Includes functions for
  - Reading IPUMS data
  - Exploring and manipulating IPUMS metadata
  - **SOON**: Interacting with the IPUMS API
    
    
???
(Metadata such as value labels, variable labels, and detailed variable 
descriptions.)

Initial API support will be for IPUMS USA, with more projects to follow soon.



---

# Why use ipumsr?

- One package for IPUMS microdata, aggregate data, and geography

???
Regarding "One package": Without ipumsr, you'd need to use a variety of
different approaches from different packages to read in and explore IPUMS
microdata (from projects such as IPUMS USA, CPS, and International), IPUMS
aggregate data (from NHGIS or IHGIS), and IPUMS shapefiles. ipumsr provides one
package with a consistent interface for working with all these different types
of IPUMS data.

---

class: center middle inverse
background-image: url(https://comicvine.gamespot.com/a/uploads/original/5/52246/1963701-the_one_ring_02.jpg)
background-size: cover

&lt;span role="img" aria-label="Slide background shows: The 'One Ring' from The Lord of the Rings set on a fiery background."&gt;&lt;/span&gt;

# One package to rule them all



&lt;img src="transparent_blank.png" title="Slide background shows: The 'One Ring' from The Lord of the Rings set on a fiery background." alt="Slide background shows: The 'One Ring' from The Lord of the Rings set on a fiery background." width="33" /&gt;

---

# Why use ipumsr?

- One package for IPUMS microdata, aggregate data, and geography

- Specialized functions for viewing and manipulating IPUMS metadata

--

- Bundled how-to guides (vignettes)

--

- Potential to add more features (e.g. API support); let us know what you want!
  - File an issue at https://github.com/mnpopcenter/ipumsr/issues
  - Email ipums+cran@umn.edu

???
Regarding "More features": The aforementioned IPUMS API support will be the next
big feature. Another potential new feature is adding tools for properly handling
survey weights. Let us know what would be helpful to you via GitHub or email.

---

# Why use ipumsr?

And finally... 

--

- It's fast!
  - Time to read 3 million rows with 13 variables:

<div id="qopaebvblf" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#qopaebvblf .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#qopaebvblf .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#qopaebvblf .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#qopaebvblf .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#qopaebvblf .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#qopaebvblf .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#qopaebvblf .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#qopaebvblf .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#qopaebvblf .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#qopaebvblf .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#qopaebvblf .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#qopaebvblf .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#qopaebvblf .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#qopaebvblf .gt_from_md > :first-child {
  margin-top: 0;
}

#qopaebvblf .gt_from_md > :last-child {
  margin-bottom: 0;
}

#qopaebvblf .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#qopaebvblf .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#qopaebvblf .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#qopaebvblf .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#qopaebvblf .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#qopaebvblf .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#qopaebvblf .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#qopaebvblf .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#qopaebvblf .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#qopaebvblf .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#qopaebvblf .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#qopaebvblf .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#qopaebvblf .gt_left {
  text-align: left;
}

#qopaebvblf .gt_center {
  text-align: center;
}

#qopaebvblf .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#qopaebvblf .gt_font_normal {
  font-weight: normal;
}

#qopaebvblf .gt_font_bold {
  font-weight: bold;
}

#qopaebvblf .gt_font_italic {
  font-style: italic;
}

#qopaebvblf .gt_super {
  font-size: 65%;
}

#qopaebvblf .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
</style>
<table class="gt_table">
  
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">Function</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">Time (seconds)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">With metadata?</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td class="gt_row gt_left">data.table::fread()</td>
<td class="gt_row gt_center">2.5</td>
<td class="gt_row gt_center">No</td></tr>
    <tr><td class="gt_row gt_left">vroom::vroom()</td>
<td class="gt_row gt_center">2.5</td>
<td class="gt_row gt_center">No</td></tr>
    <tr><td class="gt_row gt_left">ipumsr::read_ipums_micro()</td>
<td class="gt_row gt_center">3.3</td>
<td class="gt_row gt_center">Yes</td></tr>
    <tr><td class="gt_row gt_left">haven::read_dta()</td>
<td class="gt_row gt_center">7.8</td>
<td class="gt_row gt_center">Yes</td></tr>
    <tr><td class="gt_row gt_left">haven::read_sav()</td>
<td class="gt_row gt_center">9.4</td>
<td class="gt_row gt_center">Yes</td></tr>
    <tr><td class="gt_row gt_left">readr::read_csv()</td>
<td class="gt_row gt_center">9.8</td>
<td class="gt_row gt_center">No</td></tr>
  </tbody>
  
  
</table>
</div>

???
There are other ways to read IPUMS data into R, but ipumsr is the fastest way 
to read the data in with attached metadata, such as variable and value labels.

---

class: center, middle

# Poll: Have you used ipumsr?

---

# Installing ipumsr

```r
install.packages("ipumsr")
```

--

### Or if you want the development version


```r
if (!require(remotes)) install.packages("remotes")
remotes::install_github("mnpopcenter/ipumsr")
```

???
Now that we've convinced you of how great ipumsr is, you're probably asking 
"How do I get my hands on it?"

---

# Installing packages used in this webinar



```r


# install.packages(ipumsr)

## Tidyverse
install.packages(dplyr)
install.packages(ggplot2)
install.packages(stringr)
install.packages(purrr)

## gis
install.packages(sf)
install.packages(DT)

```

---

# Downloading your data extract

&lt;img src="download_screenshot_1.png" title="Screenshot of IPUMS data download page with the 'Download .DAT' and 'DDI' links highlighted" alt="Screenshot of IPUMS data download page with the 'Download .DAT' and 'DDI' links highlighted" width="3621" /&gt;

--

- Click the "Download .DAT" link to download the data

--

- Right-click the "DDI" link, and choose
    - "Save Link As..." (in Firefox)
    - "Save link as..." (in Chrome)
    - "Download Linked File" (in Safari)

???
Make sure to save the data and DDI files in the same location.

---

# Downloading your data extract

&lt;img src="download_screenshot_2.png" title="Screenshot of IPUMS data download page with the 'R' link highlighted" alt="Screenshot of IPUMS data download page with the 'R' link highlighted" width="3621" /&gt;

- The "R" link on the downloads page contains this helper code:


```r
# NOTE: To load data, you must download both the extract's data and the DDI
# and also set the working directory to the folder with these files (or change the path below).

if (!require("ipumsr")) stop("Reading IPUMS data into R requires the ipumsr package. It can be installed using the following command: install.packages('ipumsr')")

ddi &lt;- read_ipums_ddi("ipumsi_00059.xml")
data &lt;- read_ipums_micro(ddi)
```

???
This helper code checks that you have ipumsr installed, and if you do, it reads
in the DDI codebook and data into separate objects. As an aside, in case anyone
was curious, DDI stands for "Data Documentation Initiative" -- the DDI project
sets standards for documenting datasets, and the codebooks for most IPUMS
projects follow this standard.

We'll see this same code pattern in just a moment when we look at how to read 
in your data.

---

# Loading packages

```r
library(ipumsr)
library(dplyr)
library(ggplot2)
library(stringr)
library(sf)
library(purrr)
library(DT)
```



???
These packages are used in some of the examples we will walk through.

---


# Overview

.greyed-out[


`1.` What is IPUMS?

`2.` What is ipumsr, and why use it?

.strong[`3.` Reading data into R]

`4.` Exploring and manipulating metadata

`5.` Brief analysis example

`6.` Working with IPUMS geographic data

`7.` Preview of IPUMS API functionality

]


---

# Read in the data
- Using commands `read_ipums_ddi()` and `read_ipums_micro()`

```r
ddi &lt;- read_ipums_ddi("usa_00013.xml")

data &lt;- read_ipums_micro(ddi)
#&gt; Use of data from IPUMS-USA is subject to conditions including that users should
#&gt; cite the data appropriately. Use command `ipums_conditions()` for more details.
```

???
Here we see the same code pattern from the "R" helper file above, of reading the
metadata from the codebook into an object named "ddi", and using that object to 
read in the data.

---

# What's in that `ddi` object?


```r
names(ddi)
#&gt;  [1] "file_name"        "file_path"       
#&gt;  [3] "file_type"        "ipums_project"   
#&gt;  [5] "extract_date"     "extract_notes"   
#&gt;  [7] "rectypes"         "rectype_idvar"   
#&gt;  [9] "rectypes_keyvars" "var_info"        
#&gt; [11] "conditions"       "citation"        
#&gt; [13] "file_encoding"
```

---

# What's in that `ddi` object?


```r
ddi$var_info
#&gt; # A tibble: 12 Ã— 10
#&gt;    var_name var_label     var_desc      val_labels
#&gt;    &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt;         &lt;list&gt;    
#&gt;  1 YEAR     Census year   "YEAR reportâ€¦ &lt;tibble [â€¦
#&gt;  2 DATANUM  Data set numâ€¦ "DATANUM ideâ€¦ &lt;tibble [â€¦
#&gt;  3 SERIAL   Household seâ€¦ "SERIAL is aâ€¦ &lt;tibble [â€¦
#&gt;  4 HHWT     Household weâ€¦ "HHWT indicaâ€¦ &lt;tibble [â€¦
#&gt;  5 STATEFIP State (FIPS â€¦ "STATEFIP reâ€¦ &lt;tibble [â€¦
#&gt;  6 CONSPUMA Consistent Pâ€¦ "CONSPUMA idâ€¦ &lt;tibble [â€¦
#&gt;  7 GQ       Group quarteâ€¦ "GQ classifiâ€¦ &lt;tibble [â€¦
#&gt;  8 PHONE    Telephone avâ€¦ "PHONE indicâ€¦ &lt;tibble [â€¦
#&gt;  9 PERNUM   Person numbeâ€¦ "PERNUM numbâ€¦ &lt;tibble [â€¦
#&gt; 10 PERWT    Person weight "PERWT indicâ€¦ &lt;tibble [â€¦
#&gt; 11 EDUC     Educational â€¦ "EDUC indicaâ€¦ &lt;tibble [â€¦
#&gt; 12 EDUCD    Educational â€¦ "EDUC indicaâ€¦ &lt;tibble [â€¦
#&gt; # â€¦ with 6 more variables: code_instr &lt;chr&gt;,
#&gt; #   start &lt;dbl&gt;, end &lt;dbl&gt;, imp_decim &lt;dbl&gt;,
#&gt; #   var_type &lt;chr&gt;, rectypes &lt;lgl&gt;
```


???
You don't need to know this to use ipumsr, but it might help you understand 
what is going on when you read in the DDI codebook and then the data.


---

# What's in my extract again?

--

Maybe I wrote an informative extract description?




```r
ddi$extract_notes %&gt;% strwrap(30)
#&gt; [1] "User-provided description:"   
#&gt; [2] "Revision of(Revision"         
#&gt; [3] "of(Revision of(Revision of(my"
#&gt; [4] "extract))))"
```

--

No such luck ðŸ˜ž

---

# What's in my extract again?

We can print the names of our variables:

--


```r
names(data)
#&gt;  [1] "YEAR"     "DATANUM"  "SERIAL"   "HHWT"    
#&gt;  [5] "STATEFIP" "CONSPUMA" "GQ"       "PHONE"   
#&gt;  [9] "PERNUM"   "PERWT"    "EDUC"     "EDUCD"
```


But often variable names aren't self-explanatory.

--

Let's leverage that attached metadata.


---



# Overview

.greyed-out[


`1.` What is IPUMS?

`2.` What is ipumsr, and why use it?

`3.` Reading data into R

.strong[`4.` Exploring and manipulating metadata]

`5.` Brief analysis example

`6.` Working with IPUMS geographic data

`7.` Preview of IPUMS API functionality

]

---

# Available metadata
- Some (but not all) of the documentation comes with the ddi.

```r
ipums_var_label(ddi, PHONE)
#&gt; [1] "Telephone availability"

ipums_var_desc(ddi, PHONE) %&gt;% strwrap(60)
#&gt; [1] "PHONE indicates whether residents of the housing unit had"
#&gt; [2] "telephone access."
```

---

# Available metadata

```r
ipums_val_labels(ddi, PHONE)
#&gt; # A tibble: 4 Ã— 2
#&gt;     val lbl                           
#&gt;   &lt;dbl&gt; &lt;chr&gt;                         
#&gt; 1     0 N/A                           
#&gt; 2     1 No, no phone available        
#&gt; 3     2 Yes, phone available          
#&gt; 4     8 Suppressed (2012 and 2015 ACS)
```

---


# A nicer view of metadata


```r
ipums_view(ddi)
```

&lt;img src="ipums_view_screenshot.png" title="Screenshot of static html page generated by function 'ipums_view', showing variable label and variable description for the variable 'PHONE'." alt="Screenshot of static html page generated by function 'ipums_view', showing variable label and variable description for the variable 'PHONE'." width="1056" /&gt;

???
The function ipums_view() makes a nicely-formatted static html page that allows 
you to browse the metadata associated with your data extract.

---


# Data
A regular `tbl_df` data.frame

```r
data
#&gt; # A tibble: 1,476,443 Ã— 12
#&gt;     YEAR DATANUM SERIAL  HHWT    STATEFIP CONSPUMA
#&gt;    &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;int+lbl&gt;    &lt;dbl&gt;
#&gt;  1  1960       1 336455   100 27 [Minnesâ€¦       NA
#&gt;  2  1960       1 336455   100 27 [Minnesâ€¦       NA
#&gt;  3  1960       1 336456   100 27 [Minnesâ€¦       NA
#&gt;  4  1960       1 336456   100 27 [Minnesâ€¦       NA
#&gt;  5  1960       1 336456   100 27 [Minnesâ€¦       NA
#&gt;  6  1960       1 336456   100 27 [Minnesâ€¦       NA
#&gt;  7  1960       1 336457    99 27 [Minnesâ€¦       NA
#&gt;  8  1960       1 336457    99 27 [Minnesâ€¦       NA
#&gt;  9  1960       1 336457    99 27 [Minnesâ€¦       NA
#&gt; 10  1960       1 336458   100 27 [Minnesâ€¦       NA
#&gt; # â€¦ with 1,476,433 more rows, and 6 more
#&gt; #   variables: GQ &lt;int+lbl&gt;, PHONE &lt;int+lbl&gt;,
#&gt; #   PERNUM &lt;dbl&gt;, PERWT &lt;dbl&gt;, EDUC &lt;int+lbl&gt;,
#&gt; #   EDUCD &lt;int+lbl&gt;
```

---

# Wrangling value labels

- IPUMS value labels don't translate that well to R's factors.

    - (Factors always have a label, and always have values starting at 1)
  
- So `ipumsr` imports them as `haven::labelled()` objects, which aren't
  always the easiest to deal with.

- Luckily ipumsr provides helpers that allow you to use information
  from both the value and label



---

# `as_factor()`
- `as_factor()` (from haven) converts directly to a factor.


```r
ipums_val_labels(data$GQ)
#&gt; # A tibble: 7 Ã— 2
#&gt;     val lbl                                       
#&gt;   &lt;int&gt; &lt;chr&gt;                                     
#&gt; 1     0 Vacant unit                               
#&gt; 2     1 Households under 1970 definition          
#&gt; 3     2 Additional households under 1990 definitiâ€¦
#&gt; 4     3 Group quarters--Institutions              
#&gt; 5     4 Other group quarters                      
#&gt; 6     5 Additional households under 2000 definitiâ€¦
#&gt; 7     6 Fragment
```

---

# `as_factor()`

- Suppose we want to keep these labels exactly as they are.


```r
data$GQ2 &lt;- as_factor(data$GQ)
```

. . .

<div id="htmlwidget-0c35eddd258fb2d12200" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-0c35eddd258fb2d12200">{"x":{"filter":"none","vertical":false,"data":[["[0] Vacant unit","[1] Households under 1970 definition","[2] Additional households under 1990 definition","[3] Group quarters--Institutions","[4] Other group quarters","[5] Additional households under 2000 definition","[6] Fragment"],["Vacant unit","Households under 1970 definition","Additional households under 1990 definition","Group quarters--Institutions","Other group quarters","Additional households under 2000 definition","Fragment"],[0,1433423,1712,19592,21541,175,0]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>before ([val] label)<\/th>\n      <th>after<\/th>\n      <th>count<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"scrollY":"200px","scrollCollapse":true,"paging":false,"bInfo":false,"columnDefs":[{"className":"dt-right","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>

---

# `lbl_clean()`
- `lbl_clean()` gets rid of unused value labels.


```r
ipums_val_labels(data$STATEFIP)
#&gt; # A tibble: 62 Ã— 2
#&gt;      val lbl                 
#&gt;    &lt;int&gt; &lt;chr&gt;               
#&gt;  1     1 Alabama             
#&gt;  2     2 Alaska              
#&gt;  3     4 Arizona             
#&gt;  4     5 Arkansas            
#&gt;  5     6 California          
#&gt;  6     8 Colorado            
#&gt;  7     9 Connecticut         
#&gt;  8    10 Delaware            
#&gt;  9    11 District of Columbia
#&gt; 10    12 Florida             
#&gt; # â€¦ with 52 more rows
```

---

# `lbl_clean()`
- Since our extract only has Minnesota, we don't want all of
 these values.


```r
data$STATEFIP2 &lt;- data$STATEFIP %&gt;% 
  lbl_clean() %&gt;% 
  as_factor()
```

. . .

<div id="htmlwidget-b5c09f8c0c2ba6966166" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-b5c09f8c0c2ba6966166">{"x":{"filter":"none","vertical":false,"data":[["[27] Minnesota"],["Minnesota"],[1476443]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>before ([val] label)<\/th>\n      <th>after<\/th>\n      <th>count<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"scrollY":"200px","scrollCollapse":true,"paging":false,"bInfo":false,"columnDefs":[{"className":"dt-right","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>

---
a
# `lbl_na_if()`
- `lbl_na_if()` allows you to set certain values or labels 
  to missing.


```r
ipums_val_labels(data$PHONE)
#&gt; # A tibble: 4 Ã— 2
#&gt;     val lbl                           
#&gt;   &lt;int&gt; &lt;chr&gt;                         
#&gt; 1     0 N/A                           
#&gt; 2     1 No, no phone available        
#&gt; 3     2 Yes, phone available          
#&gt; 4     8 Suppressed (2012 and 2015 ACS)
```

---

# `lbl_na_if()`

- Easier to use R's `NA` data structure to deal with missing values
  like "N/A" and "Suppressed".


```r
data$PHONE2 &lt;- lbl_na_if(data$PHONE, ~.val %in% c(0, 8)) %&gt;%
  as_factor()
```

. . . 

<div id="htmlwidget-daeb4e589da09380ea44" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-daeb4e589da09380ea44">{"x":{"filter":"none","vertical":false,"data":[["[0] N/A","[1] No, no phone available","[2] Yes, phone available","[8] Suppressed (2012 and 2015 ACS)"],[null,"No, no phone available","Yes, phone available",null],[41133,30852,1404458,0]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>before ([val] label)<\/th>\n      <th>after<\/th>\n      <th>count<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"scrollY":"200px","scrollCollapse":true,"paging":false,"bInfo":false,"columnDefs":[{"className":"dt-right","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>

---

# `lbl_na_if()`
- It works with both values (`.val`) and labels (`.lbl`).
  So we could have also written something like this:

```r
drop_labels &lt;- c("N/A", "Suppressed (2012 and 2015 ACS)")

data$PHONE3 &lt;- lbl_na_if(data$PHONE, ~.lbl %in% drop_labels) %&gt;%
  as_factor()
```

---

# `lbl_collapse()`
- `lbl_collapse()` allows you to take advantage of the hierarchical
  structure of value labels.

```r
ipums_val_labels(data$EDUCD)
#&gt; # A tibble: 44 Ã— 2
#&gt;      val lbl                      
#&gt;    &lt;int&gt; &lt;chr&gt;                    
#&gt;  1     0 N/A or no schooling      
#&gt;  2     1 N/A                      
#&gt;  3     2 No schooling completed   
#&gt;  4    10 Nursery school to grade 4
#&gt;  5    11 Nursery school, preschool
#&gt;  6    12 Kindergarten             
#&gt;  7    13 Grade 1, 2, 3, or 4      
#&gt;  8    14 Grade 1                  
#&gt;  9    15 Grade 2                  
#&gt; 10    16 Grade 3                  
#&gt; # â€¦ with 34 more rows
```

---

# `lbl_collapse()`

- Maybe this is too much detail, so we want to collapse 
  the last digit.


```r
data$EDUCD2 &lt;- lbl_collapse(data$EDUCD, ~.val %/% 10) %&gt;%
  as_factor()
```

. . .

<div id="htmlwidget-a9d7856549aa26dd0fce" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-a9d7856549aa26dd0fce">{"x":{"filter":"none","vertical":false,"data":[["[0] N/A or no schooling","[1] N/A","[2] No schooling completed","[10] Nursery school to grade 4","[11] Nursery school, preschool","[12] Kindergarten","[13] Grade 1, 2, 3, or 4","[14] Grade 1","[15] Grade 2","[16] Grade 3","[17] Grade 4","[20] Grade 5, 6, 7, or 8","[21] Grade 5 or 6","[22] Grade 5","[23] Grade 6","[24] Grade 7 or 8","[25] Grade 7","[26] Grade 8","[30] Grade 9","[40] Grade 10","[50] Grade 11","[60] Grade 12","[61] 12th grade, no diploma","[62] High school graduate or GED","[63] Regular high school diploma","[64] GED or alternative credential","[65] Some college, but less than 1 year","[70] 1 year of college","[71] 1 or more years of college credit, no degree","[80] 2 years of college","[81] Associate's degree, type not specified","[82] Associate's degree, occupational program","[83] Associate's degree, academic program","[90] 3 years of college","[100] 4 years of college","[101] Bachelor's degree","[110] 5+ years of college","[111] 6 years of college (6+ in 1960-1970)","[112] 7 years of college","[113] 8+ years of college","[114] Master's degree","[115] Professional degree beyond a bachelor's degree","[116] Doctoral degree","[999] Missing"],["N/A or no schooling","N/A or no schooling","N/A or no schooling","Nursery school to grade 4","Nursery school to grade 4","Nursery school to grade 4","Nursery school to grade 4","Nursery school to grade 4","Nursery school to grade 4","Nursery school to grade 4","Nursery school to grade 4","Grade 5, 6, 7, or 8","Grade 5, 6, 7, or 8","Grade 5, 6, 7, or 8","Grade 5, 6, 7, or 8","Grade 5, 6, 7, or 8","Grade 5, 6, 7, or 8","Grade 5, 6, 7, or 8","Grade 9","Grade 10","Grade 11","Grade 12","Grade 12","Grade 12","Grade 12","Grade 12","Grade 12","1 year of college","1 year of college","2 years of college","2 years of college","2 years of college","2 years of college","3 years of college","4 years of college","4 years of college","5+ years of college","5+ years of college","5+ years of college","5+ years of college","5+ years of college","5+ years of college","5+ years of college","Missing"],[11811,50098,50114,40324,14976,14611,15871,10715,11500,11836,12399,27934,16637,12274,14020,28589,15962,40520,39440,46037,44797,67118,17653,170139,102651,12312,65168,13985,156110,12989,69752,9937,3888,6712,15917,147940,4280,3062,1303,1799,42621,13744,6898,0]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>before ([val] label)<\/th>\n      <th>after<\/th>\n      <th>count<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"scrollY":"200px","scrollCollapse":true,"paging":false,"bInfo":false,"columnDefs":[{"className":"dt-right","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>

---

# `lbl_relabel()`
- `lbl_relabel()` has more granular control of what the values are assigned to.


```r
levels(data$EDUCD2)
#&gt;  [1] "N/A or no schooling"      
#&gt;  [2] "Nursery school to grade 4"
#&gt;  [3] "Grade 5, 6, 7, or 8"      
#&gt;  [4] "Grade 9"                  
#&gt;  [5] "Grade 10"                 
#&gt;  [6] "Grade 11"                 
#&gt;  [7] "Grade 12"                 
#&gt;  [8] "1 year of college"        
#&gt;  [9] "2 years of college"       
#&gt; [10] "3 years of college"       
#&gt; [11] "4 years of college"       
#&gt; [12] "5+ years of college"      
#&gt; [13] "Missing"
```

---

# `lbl_relabel()`

- Maybe the education variable is still too specific.


```r
data$EDUCD3 &lt;- data$EDUCD %&gt;%
  lbl_collapse(~.val %/% 10) %&gt;% 
  lbl_relabel(
    lbl(2, "Less than High School") ~.val &gt; 0 &amp; .val &lt; 6,
    lbl(3, "High school") ~.lbl == "Grade 12",
    lbl(4, "Some college") ~str_detect(.lbl, "^[123] year(s)? of college$"),
    lbl(5, "College or more") ~.val %in% c(10, 11)
  ) %&gt;%
  as_factor()
```

---

# `lbl_relabel()`

<div id="htmlwidget-a8f9588dd31c767b7cb2" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-a8f9588dd31c767b7cb2">{"x":{"filter":"none","vertical":false,"data":[["[0] N/A or no schooling","[1] N/A","[2] No schooling completed","[10] Nursery school to grade 4","[11] Nursery school, preschool","[12] Kindergarten","[13] Grade 1, 2, 3, or 4","[14] Grade 1","[15] Grade 2","[16] Grade 3","[17] Grade 4","[20] Grade 5, 6, 7, or 8","[21] Grade 5 or 6","[22] Grade 5","[23] Grade 6","[24] Grade 7 or 8","[25] Grade 7","[26] Grade 8","[30] Grade 9","[40] Grade 10","[50] Grade 11","[60] Grade 12","[61] 12th grade, no diploma","[62] High school graduate or GED","[63] Regular high school diploma","[64] GED or alternative credential","[65] Some college, but less than 1 year","[70] 1 year of college","[71] 1 or more years of college credit, no degree","[80] 2 years of college","[81] Associate's degree, type not specified","[82] Associate's degree, occupational program","[83] Associate's degree, academic program","[90] 3 years of college","[100] 4 years of college","[101] Bachelor's degree","[110] 5+ years of college","[111] 6 years of college (6+ in 1960-1970)","[112] 7 years of college","[113] 8+ years of college","[114] Master's degree","[115] Professional degree beyond a bachelor's degree","[116] Doctoral degree","[999] Missing"],["N/A or no schooling","N/A or no schooling","N/A or no schooling","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","High school","High school","High school","High school","High school","High school","Some college","Some college","Some college","Some college","Some college","Some college","Some college","College or more","College or more","College or more","College or more","College or more","College or more","College or more","College or more","College or more","Missing"],[11811,50098,50114,40324,14976,14611,15871,10715,11500,11836,12399,27934,16637,12274,14020,28589,15962,40520,39440,46037,44797,67118,17653,170139,102651,12312,65168,13985,156110,12989,69752,9937,3888,6712,15917,147940,4280,3062,1303,1799,42621,13744,6898,0]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>before ([val] label)<\/th>\n      <th>after<\/th>\n      <th>count<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"scrollY":"200px","scrollCollapse":true,"paging":false,"bInfo":false,"columnDefs":[{"className":"dt-right","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>






---


# Overview

.greyed-out[


`1.` What is IPUMS?

`2.` What is ipumsr, and why use it?

`3.` Reading data into R

`4.` Exploring and manipulating metadata

.strong[`5.` Brief analysis example]

`6.` Working with IPUMS geographic data

`7.` Preview of IPUMS API functionality

]





---

# Phone availability 
- Now that they're factors, ready for use as regular R data

```r
graph_data &lt;- data %&gt;%
  group_by(YEAR) %&gt;%
  summarize(`% with phone` = weighted.mean(
    PHONE2 == "Yes, phone available", PERWT, na.rm = TRUE
  ))

ggplot(graph_data, aes(x = YEAR, y = `% with phone`)) +
  geom_point() +
  geom_line() + 
  labs(
    title = "Percent of Minnesota with phone line",
    subtitle = paste0("Data source: ", ddi$ipums_project),
    caption = paste(strwrap(ipums_var_desc(ddi, PHONE), 90), collapse = "\n")
  )
```

---

# Phone availability
![](ipumsr_webinar_files/figure-html/graph1-1.png)&lt;!-- --&gt;

---

# Interpretation

&gt; The 2008 ACS and 2008 PRCS instructed respondents to include cell 
&gt; phone service; prior to 2008, this was not made explicit.
&gt; 
&gt; - https://usa.ipums.org/usa-action/variables/PHONE#comparability_section

---

# Phone availability by education
![](ipumsr_webinar_files/figure-html/graph2-1.png)&lt;!-- --&gt;

---

# Overview

.greyed-out[


`1.` What is IPUMS?

`2.` What is ipumsr, and why use it?

`3.` Reading data into R

`4.` Exploring and manipulating metadata

`5.` Brief analysis example

.strong[`6.` Working with IPUMS geographic data]

`7.` Preview of IPUMS API functionality

]



---

# Getting geographic data

- For IPUMS USA (and several other projects), we provide geographic boundaries 
  as well. For many areas, this includes harmonizing boundary changes over time.

- Our extract includes the variable CONSPUMA, for "Consistent Public Use 
  Microdata Areas"

- Note: CONSPUMA units are large
  - For finer geographic detail, check out IPUMS NHGIS

???
Geographic boundary data is usually found via a "Geography and GIS" link on the
left sidebar of the home page for a data collection, under the heading
"Supplemental Data".

---

# Loading shape data

- `ipumsr` provides support for both sf and sp data; we'll use sf here

- Load with the `ipums_read_sf()` function (mostly just a wrapper around
  `sf::read_sf()`)



```r
shape_data &lt;- read_ipums_sf("shape/")
#&gt; options:        ENCODING=latin1 
#&gt; Reading layer `ipums_conspuma' from data source 
#&gt;   `/Users/Kara/Documents/Projects/ipumsr-webinar/shape/ipums_conspuma.shp' 
#&gt;   using driver `ESRI Shapefile'
#&gt; Simple feature collection with 543 features and 3 fields
#&gt; Geometry type: MULTIPOLYGON
#&gt; Dimension:     XY
#&gt; Bounding box:  xmin: -7115713 ymin: -1337508 xmax: 2258225 ymax: 4591616
#&gt; Projected CRS: USA_Contiguous_Albers_Equal_Area_Conic
```

???
The sp package (short for "spatial") has been around since 2005. It is more
established and some other R spatial packages might still assume you are using
sp data structures. The sf package (short for "simple features") is newer, but 
seems to be on the rise as an alternative sp for some use cases.

---

# Loading shape data


```r
as_tibble(shape_data)
#&gt; # A tibble: 543 Ã— 4
#&gt;    CONSPUMA STATEFIP State     
#&gt;       &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;     
#&gt;  1      540 02       Alaska    
#&gt;  2      541 02       Alaska    
#&gt;  3      542 15       Hawaii    
#&gt;  4      491 51       Virginia  
#&gt;  5      492 51       Virginia  
#&gt;  6      493 51       Virginia  
#&gt;  7      494 51       Virginia  
#&gt;  8      495 53       Washington
#&gt;  9      496 53       Washington
#&gt; 10      497 53       Washington
#&gt; # â€¦ with 533 more rows, and 1 more variable:
#&gt; #   geometry &lt;MULTIPOLYGON [m]&gt;
```
???
At the risk of oversimplifying, an sf object is basically a tibble or data.frame
with a special geometry column. That simplification helps me understand the 
process of joining the sf object to data.

---

# Joining shape data
- `ipumsr` has helpers for merging data that work with both sf and sp structures 


```r
conspuma_data &lt;- data %&gt;%
  group_by(CONSPUMA, YEAR) %&gt;%
  summarize(
    PHONE = weighted.mean(
      PHONE2 == "Yes, phone available", PERWT, na.rm = TRUE
    ),
    .groups = "drop"
  )

conspuma_data &lt;- ipums_shape_inner_join(
  conspuma_data, 
  shape_data, 
  by = "CONSPUMA"
)
#&gt; Some observations were lost in the join (533 observations in the shape file and
#&gt; 11 obervation in data). See `join_failures(...)` for more details.
```

???
Before joining to shape data, we need to summarize our person level data at the 
level of the geography we are joining to. Thus, the first block of code computes 
the weighted proportion of persons with access to a phone for each CONSPUMA 
unit in each year. Once our data are summarized so that each row represents a 
value for one CONSPUMA unit in one year, we can join to the sf object we loaded 
above.

---

# Plotting shape data
- Since the addition of `geom_sf()`, ggplot2 can plot sf data:
![](ipumsr_webinar_files/figure-html/graph3-1.png)&lt;!-- --&gt;

???
For more information on IPUMS geographic data, see the ipumsr vignette on
working with geographic data, or one of several collection-specific recorded
webinars on that topic.

---
# Overview

.greyed-out[


`1.` What is IPUMS?

`2.` What is ipumsr, and why use it?

`3.` Reading data into R

`4.` Exploring and manipulating metadata

`5.` Brief analysis example

`6.` Working with IPUMS geographic data

.strong[`7.` Preview of IPUMS API functionality]

]


---

# API Timeline

- Currently in internal testing

- Beta testing before the end of 2021

- IPUMS USA public launch early 2022

???
The API is not yet publicly available, but we wanted to offer a preview of the 
functionality that will soon be available in ipumsr.

We plan to support creating extracts via API for all of our data collections, 
but that support will be rolled out one collection at a time, to allow us to 
thoroughly test that the extract API is working as expected for each collection.

IPUMS USA is the first collection that will be supported, and we are currently
doing internal testing of the API for USA. We'll put out a call for beta testers
before the end of this year, but feel free to reach out in the meantime if you
want to be added to that list. We expect to open up the USA extract API to all
IPUMS USA users in the first few months of next year, depending on what sort of
issues arise during beta testing.

Another important note is that there is already a public API for the IPUMS NHGIS
collection, which offers access to tabular data from the US Census Bureau, as
well as corresponding geographic boundaries. ipumsr does not yet include
functions for interacting with the NHGIS API, but there is a guide to
interacting with that API in R, which we'll share a link to at the end of these
slides, and we plan to add that functionality to ipumsr sometime next year.

---

# What can I do with the API?

- Define and submit extract requests

--

- Check extract status or "wait" for an extract to finish

--

- Download completed extracts

--

- Get info on past extracts

--

- Share extract definitions

???
So, your next question might be, "what will I be able to do with this API?" 
Here's the high-level overview:

You'll be able to:

Define and submit extract requests.

Check the status of a submitted extract, or have R "wait" for an extract to 
finish by periodically checking the status until it is ready to download.

Download completed data extracts.

Get information on past extracts, including the ability to pull down the 
definition of a previous extract, revise that definition, and resubmit it.

And finally, you can save your extract definition to a JSON file, allowing you 
to share the extract definition with other users for collaboration or 
reproducibility. Saving as JSON makes the definition more easily shareable 
across languages, since R is not the only way to interact with the IPUMS API -- 
you can also call the API using a general purpose tool like curl, and IPUMS is 
developing API client tools for Python in parallel with the R client tools that 
will be part of the ipumsr package.

---

# What can't I do with the API?

- Bypass the extract system entirely

--

- Explore what data are available

--

- Use all features of the extract system (at least not right away)


???
The other important question to answer is what the API can't do.

Most importantly, it can't deliver data "on demand" -- extracts are still 
created through the same extract system used by the website, which means you 
have to wait for your extract to process before you can download it.

In other words, the API does not create a separate system of accessing IPUMS
data, but rather provides a programmatic way to create and download extracts
through the existing extract system.

Secondly, you can't use the API to explore what data are available from IPUMS. 
We plan to add a public metadata API, but the timeline on that is more unknown.

A third limitation is that API users will not initially have access to all the
bells and whistles of the extract system, such as the ability to attach 
characteristics of family members such as spouses or children. We plan to add 
these capabilities once the core functionality is well-tested and stable.

---

# Pipe-friendly example


```r
my_extract &lt;- define_extract(
  "usa", 
  "Occupation by sex and age",
  c("us2017a", "us2018a"), 
  c("SEX", "AGE", "IND", "OCC")
)
```

--

Extract definition to data in one piped expression!


```r
data &lt;- my_extract %&gt;% 
  submit_extract() %&gt;% 
  wait_for_extract() %&gt;% 
  download_extract() %&gt;% 
  read_ipums_micro()
```

???
Now let's get to some example code! We'll start with a brief example that shows 
a typical API workflow using the "pipe" operator from the magrittr package, 
which is often used in conjunction with tidyverse packages such as dplyr.

We start by defining an extract object using the `define_extract()` function, 
and specifying 

- a data collection -- in this case, "usa" 
- an extract description -- "Occupation by sex and age"
- samples -- here we're asking for the 2017 and 2018 American Community Survey 
- and variables -- sex, age, industry and occupation.

The next code chunk shows how we can go from this extract definition to having 
our extract data available in our R session in one piped expression. For any of 
you who are unfamiliar with the pipe operator, it can be read aloud as the word 
"then". So this piped expression says, take "my_extract", *then* submit extract, 
*then* wait for extract, *then* download extract, *then* read in the data using 
`read_ipums_micro()`.

Since we have to wait for the extract to process, this piped expression will 
take a bit of time to execute, depending on the size of your extract, but if we 
have time we will actually run some code like this during the Q&amp;A so you can 
see it in action.

---

# Pipe-friendly example


```r
my_extract &lt;- define_extract(
  "usa", 
  "Occupation by sex and age",
  c("us2017a", "us2018a"), 
  c("SEX", "AGE", "IND", "OCC")
)
```

Extract definition to data in one piped expression!


```r
data &lt;- my_extract |&gt; 
  submit_extract() |&gt; 
  wait_for_extract() |&gt; 
  download_extract() |&gt; 
  read_ipums_micro()
```


???
And just for fun, here's what the same piped expression looks like with the new
base R pipe, available as of R 4.1.

---

# Revise and resubmit

Get definition of my most recent extract:


```r
old_extract &lt;- get_recent_extracts_info_list("usa", 1)[[1]]
```

--

Or if we know the number of the extract:


```r
old_extract &lt;- get_extract_info("usa:33")
```


???
Another handy workflow where using the extract API is a "revise and resubmit" 
workflow. Often, you might realize that you should have added one more or a few 
more variables to your previous extract, and you just want to resubmit that 
extract with a few additional variables.

To do this with ipumsr functions, you first pull down the definition of your 
most recent extract using the function `get_recent_extracts_info_list()`, which 
can return information on up to 10 recent extracts. Here, we specify that we 
only want one recent extract (the most recent one), but because this function 
always returns a list, we also have to subset the first element.

Alternatively, if we know the extract number of the extract we want to revise, 
we can use `get_extract_info()` and specify a shorthand notation for USA 
extract number 33, for example.

---

# Revise and resubmit

Then add a variable and resubmit:


```r
old_extract %&gt;% 
  revise_extract(vars_to_add = "EDUC") %&gt;% 
  submit_extract()
```

???
Once we have the old extract definition, we can pass it to the 
`revise_extract()` function to add a variable, then resubmit it.

The `revise_extract()` function currently allows you to add and remove variables
and samples, as well as change the description, data format, or data structure
of your extract definition.

---

# Share your extract definition


```r
save_extract_as_json(my_extract, "my_extract.json")
```

--

Another user can read that definition back in with:


```r
cloned_extract &lt;- define_extract_from_json("my_extract.json", "usa")
```

???
One thing that really excites us about the API is the ability to share extract
definitions to facilitate collaboration or reproducibility.

To write your extract out to a JSON file, you can use the 
`save_extract_as_json()` function as shown here.

Saving as JSON makes it easier to share an extract definition with another user 
who might not use R -- they can use the JSON definition to submit the extract 
using curl or Python, possibly using the currently in-development IPUMS API 
client tools in the "ipumspy" module.

If you are using ipumsr, the `define_extract_from_json()` function will create
an extract object from a JSON-formatted definition shared by someone else.

---

# Resources
- Email us: ipums+cran@umn.edu

- ipumsr github: https://github.com/mnpopcenter/ipumsr

- This presentation: https://github.com/dtburk/ipumsr-webinar

- ipumsr website, with vignettes: http://tech.popdata.org/ipumsr/index.html

- IPUMS tutorials page: https://www.ipums.org/support/tutorials

- *Geocomputation with R* book: https://geocompr.robinlovelace.net/
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
